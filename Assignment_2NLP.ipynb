{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmanSalah2000/similar_documents/blob/main/Assignment_2NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63624a7b",
      "metadata": {
        "id": "63624a7b"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade pip\n",
        "# !pip install wikipedia\n",
        "# !pip install gensim\n",
        "# !pip install spacy\n",
        "# !pip install --upgrade gensim\n",
        "# !python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b8a6271",
      "metadata": {
        "id": "7b8a6271",
        "outputId": "3ddfe4cf-c452-4895-9634-c8c10260fcac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Eman\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
            "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Eman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wikipedia\n",
        "import gensim\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "from gensim.models import  Word2Vec , KeyedVectors\n",
        "import spacy\n",
        "import en_core_web_md\n",
        "import re\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import nltk\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.decomposition import PCA\n",
        "import csv\n",
        "import pandas as pd\n",
        "import os\n",
        "nltk.download('stopwords')\n",
        "# nltk.download('WordNetLemmatizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c287a4c0",
      "metadata": {
        "id": "c287a4c0"
      },
      "outputs": [],
      "source": [
        "def generte_doc(phrase,sentence):\n",
        "    document=wikipedia.summary(phrase, sentences = sentence)\n",
        "    return document\n",
        "\n",
        "def preproccessing(corpus):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    corpus=re.sub(pattern=r'[\\!\"#$%&\\*+,-./:;<=>?@^_`()|~=]', repl='', string=corpus.lower()).strip().split(' ')\n",
        "    new_corpus=[]\n",
        "    for word in corpus :\n",
        "        word=lemmatizer.lemmatize(word)\n",
        "        if word not in stop_words:       \n",
        "            new_corpus.append(word)\n",
        "    corpus=new_corpus\n",
        "    return corpus\n",
        "\n",
        "def average(document):\n",
        "    temp_list=[]\n",
        "    for j  in range(len(document)):\n",
        "         temp_list.append(document[j].vector)\n",
        "    temp_list=np.array(temp_list)\n",
        "    print(temp_list.shape)\n",
        "    documents_ID=np.mean(temp_list,axis=0)\n",
        "    \n",
        "    return documents_ID \n",
        "\n",
        "def rebypca(document):\n",
        "    temp_list=[]\n",
        "    for j  in range(len(document)):\n",
        "         temp_list.append(document[j].vector)\n",
        "    # for example 165  300 \n",
        "    #  300 165 \n",
        "    # 300 ,1 \n",
        "    temp_list=np.array(temp_list)\n",
        "    print(temp_list.shape)\n",
        "    pca = PCA(n_components = 1)\n",
        "    temp_list=np.transpose(temp_list)\n",
        "    print(temp_list.shape)\n",
        "    documents_ID = pca.fit_transform(temp_list)\n",
        "    documents_ID=documents_ID.reshape(len(documents_ID))\n",
        "    return documents_ID "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fafb3d9",
      "metadata": {
        "id": "8fafb3d9"
      },
      "outputs": [],
      "source": [
        "# domain_1 operating system\n",
        "doc_1=generte_doc(\"windows operating system\",6)\n",
        "doc_2=generte_doc(\"linux operating system\",6)\n",
        "doc_3=generte_doc(\"uniux operating system\",6)\n",
        "doc_4=generte_doc(\"mac operating system\",6)\n",
        "\n",
        "# domain_2 virus\n",
        "doc_5=generte_doc(\"corona virus\",6)\n",
        "doc_6=generte_doc(\"bird flu virus\",6)\n",
        "doc_7=generte_doc(\"Hepatitis C virus\",6)\n",
        "\n",
        "\n",
        "# domain_3 programming language\n",
        "doc_8=generte_doc(\"python programming language\",6)\n",
        "doc_9=generte_doc(\"c++ programming language\",6)\n",
        "doc_10=generte_doc(\"c# programming language\",6)\n",
        "doc_11=generte_doc(\"java  programming language\",6)\n",
        "doc_12=generte_doc(\"kotlin  programming language\",6)\n",
        "\n",
        "#  domain_4 fruits\n",
        "doc_13=generte_doc(\"mango\",6)\n",
        "doc_14=generte_doc(\"watermelon\",6)\n",
        "doc_15=generte_doc(\"apple \",6)\n",
        "doc_16=generte_doc(\"strawberry\",6)\n",
        "\n",
        "\n",
        "#domain _5 types of smartphones \n",
        "doc_17=generte_doc(\"samsung smartphones\",6)\n",
        "doc_18=generte_doc(\"oppo smartphones\",6)\n",
        "doc_19=generte_doc(\"Huawei smartphones\",6)\n",
        "doc_20=generte_doc(\"Xiaomi smartphones\",6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0fdba62",
      "metadata": {
        "id": "e0fdba62"
      },
      "outputs": [],
      "source": [
        "# model_gensim=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39355606",
      "metadata": {
        "id": "39355606"
      },
      "outputs": [],
      "source": [
        "model_spacy=spacy.load(\"en_core_web_md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b3883cd",
      "metadata": {
        "id": "2b3883cd"
      },
      "outputs": [],
      "source": [
        "all_doc_list=[doc_1,doc_2,doc_3,doc_4,doc_5,doc_6,doc_7,doc_8,doc_9,doc_10,\n",
        "              doc_11,doc_12,doc_13,doc_14,doc_15,doc_16,doc_17,doc_18,doc_19,doc_20]\n",
        "\n",
        "for i  in range(20):\n",
        "       all_doc_list[i]=preproccessing(all_doc_list[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e16b2a8d",
      "metadata": {
        "id": "e16b2a8d",
        "outputId": "fdf77f9e-9c5b-4db3-89f3-f572b9cda403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(334, 300)\n",
            "(300, 334)\n",
            "(381, 300)\n",
            "(300, 381)\n",
            "(539, 300)\n",
            "(300, 539)\n",
            "(418, 300)\n",
            "(300, 418)\n",
            "(256, 300)\n",
            "(300, 256)\n",
            "(289, 300)\n",
            "(300, 289)\n",
            "(253, 300)\n",
            "(300, 253)\n",
            "(317, 300)\n",
            "(300, 317)\n",
            "(321, 300)\n",
            "(300, 321)\n",
            "(391, 300)\n",
            "(300, 391)\n",
            "(379, 300)\n",
            "(300, 379)\n",
            "(508, 300)\n",
            "(300, 508)\n",
            "(323, 300)\n",
            "(300, 323)\n",
            "(269, 300)\n",
            "(300, 269)\n",
            "(283, 300)\n",
            "(300, 283)\n",
            "(425, 300)\n",
            "(300, 425)\n",
            "(525, 300)\n",
            "(300, 525)\n",
            "(285, 300)\n",
            "(300, 285)\n",
            "(213, 300)\n",
            "(300, 213)\n",
            "(359, 300)\n",
            "(300, 359)\n",
            "(20, 300)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close()>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents_IDs=np.zeros([20,300])\n",
        "file_csv=open(\"output.csv\",\"w\")\n",
        "\n",
        "# file_txt=open(\"output.txt\",\"w\")\n",
        "\n",
        "documents_name = ['doc_1','doc_2','doc_3','doc_4','doc_5','doc_6','doc_7','doc_8','doc_9','doc_10',\n",
        "              'doc_11','doc_12','doc_13','doc_14','doc_15','doc_16','doc_17','doc_18','doc_19','doc_20']\n",
        "writer = csv.DictWriter(file_csv,fieldnames=['name','vector'])\n",
        "writer.writeheader()\n",
        "for i in range(len(documents_name)):\n",
        "   \n",
        "    document_vectors=model_spacy(str(all_doc_list[i])) \n",
        "#     documents_IDs[i]=average(document_vectors)\n",
        "    documents_IDs[i]=rebypca(document_vectors)    \n",
        "    writer.writerow({'name':documents_name[i],'vector':[x for x in documents_IDs[i]]})\n",
        " \n",
        "\n",
        "\n",
        "  \n",
        "print(documents_IDs.shape)\n",
        "file_csv.close\n",
        "# file_txt.close\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f5ac95f",
      "metadata": {
        "id": "7f5ac95f",
        "outputId": "e62de773-2925-4178-bc60-4465906ceab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(229, 300)\n",
            "(300, 229)\n",
            "(300,)\n"
          ]
        }
      ],
      "source": [
        "# phrase=input(\"enter a new phrase\")\n",
        "phrase=\"banana is very good\"\n",
        "document=model_spacy(str(preproccessing(generte_doc(phrase,3))))\n",
        "\n",
        "# temp_list=average(document)\n",
        "temp_list=rebypca(document)\n",
        "print(temp_list.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noDRqa_6H_Bl",
        "outputId": "34b8398a-c620-4759-e5aa-ffd260f425f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(229, 300)\n",
            "(300, 229)\n",
            "(300,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# temp_list=average(document)\n",
        "temp_list=rebypca(document)\n",
        "print(temp_list.shape)"
      ],
      "id": "noDRqa_6H_Bl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34a171e4",
      "metadata": {
        "id": "34a171e4",
        "outputId": "74361775-c158-41ff-800a-113ea594a2ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>doc_1</td>\n",
              "      <td>[-3.2603836059570312, 7.726551532745361, 0.715...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>doc_2</td>\n",
              "      <td>[-3.755075454711914, 8.262920379638672, 0.8364...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>doc_3</td>\n",
              "      <td>[-4.335402965545654, 9.939878463745117, 1.0609...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>doc_4</td>\n",
              "      <td>[-3.8410048484802246, 8.8040771484375, 0.85038...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>doc_5</td>\n",
              "      <td>[-3.144298791885376, 6.821199417114258, 0.5313...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>doc_6</td>\n",
              "      <td>[-3.7309043407440186, 7.176026821136475, 0.507...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>doc_7</td>\n",
              "      <td>[-3.1826558113098145, 6.913822650909424, 0.505...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>doc_8</td>\n",
              "      <td>[-3.346261739730835, 7.502175331115723, 0.8112...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>doc_9</td>\n",
              "      <td>[-3.332167148590088, 7.5640788078308105, 0.828...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>doc_10</td>\n",
              "      <td>[-3.756667375564575, 8.320206642150879, 0.7777...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>doc_11</td>\n",
              "      <td>[-3.623166084289551, 8.130351066589355, 0.7627...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>doc_12</td>\n",
              "      <td>[-4.162985324859619, 9.543931007385254, 0.8536...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>doc_13</td>\n",
              "      <td>[-3.3220303058624268, 7.636740684509277, 0.789...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>doc_14</td>\n",
              "      <td>[-3.2111034393310547, 7.080463409423828, 0.644...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>doc_15</td>\n",
              "      <td>[-3.086650848388672, 7.11014461517334, 0.64121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>doc_16</td>\n",
              "      <td>[-3.9162962436676025, 8.889816284179688, 0.824...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>doc_17</td>\n",
              "      <td>[-4.201286315917969, 9.796714782714844, 0.9911...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>doc_18</td>\n",
              "      <td>[-3.179405927658081, 7.309471607208252, 0.7809...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>doc_19</td>\n",
              "      <td>[-2.7913057804107666, 6.211474418640137, 0.705...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>doc_20</td>\n",
              "      <td>[-3.5531251430511475, 8.128832817077637, 0.854...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      name                                             vector\n",
              "0    doc_1  [-3.2603836059570312, 7.726551532745361, 0.715...\n",
              "1    doc_2  [-3.755075454711914, 8.262920379638672, 0.8364...\n",
              "2    doc_3  [-4.335402965545654, 9.939878463745117, 1.0609...\n",
              "3    doc_4  [-3.8410048484802246, 8.8040771484375, 0.85038...\n",
              "4    doc_5  [-3.144298791885376, 6.821199417114258, 0.5313...\n",
              "5    doc_6  [-3.7309043407440186, 7.176026821136475, 0.507...\n",
              "6    doc_7  [-3.1826558113098145, 6.913822650909424, 0.505...\n",
              "7    doc_8  [-3.346261739730835, 7.502175331115723, 0.8112...\n",
              "8    doc_9  [-3.332167148590088, 7.5640788078308105, 0.828...\n",
              "9   doc_10  [-3.756667375564575, 8.320206642150879, 0.7777...\n",
              "10  doc_11  [-3.623166084289551, 8.130351066589355, 0.7627...\n",
              "11  doc_12  [-4.162985324859619, 9.543931007385254, 0.8536...\n",
              "12  doc_13  [-3.3220303058624268, 7.636740684509277, 0.789...\n",
              "13  doc_14  [-3.2111034393310547, 7.080463409423828, 0.644...\n",
              "14  doc_15  [-3.086650848388672, 7.11014461517334, 0.64121...\n",
              "15  doc_16  [-3.9162962436676025, 8.889816284179688, 0.824...\n",
              "16  doc_17  [-4.201286315917969, 9.796714782714844, 0.9911...\n",
              "17  doc_18  [-3.179405927658081, 7.309471607208252, 0.7809...\n",
              "18  doc_19  [-2.7913057804107666, 6.211474418640137, 0.705...\n",
              "19  doc_20  [-3.5531251430511475, 8.128832817077637, 0.854..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=pd.read_csv(\"output.csv\")\n",
        "data=pd.DataFrame(data)\n",
        "data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e43f2ff7",
      "metadata": {
        "id": "e43f2ff7",
        "outputId": "3e04c3e2-6315-4475-bba0-808052418d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "300\n",
            "300\n"
          ]
        }
      ],
      "source": [
        "print(len(data['vector'][0].split(',')))\n",
        "print(len(temp_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88327417",
      "metadata": {
        "id": "88327417",
        "outputId": "1f93c084-d3f7-402e-ec47-d726ac087fd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 3.          0.99967817]\n",
            " [19.          0.99965515]\n",
            " [ 8.          0.99962398]\n",
            " [13.          0.99961436]\n",
            " [20.          0.99961111]\n",
            " [ 4.          0.99959234]\n",
            " [18.          0.99958563]\n",
            " [15.          0.99956035]\n",
            " [10.          0.9995554 ]\n",
            " [ 5.          0.99953916]\n",
            " [16.          0.99952715]\n",
            " [14.          0.99950556]\n",
            " [12.          0.99949911]\n",
            " [ 2.          0.99949824]\n",
            " [17.          0.99949038]\n",
            " [ 1.          0.9994576 ]\n",
            " [11.          0.99945667]\n",
            " [ 7.          0.9994182 ]\n",
            " [ 9.          0.999307  ]\n",
            " [ 6.          0.99818312]]\n"
          ]
        }
      ],
      "source": [
        "similar_documents=np.zeros([20,2])\n",
        "\n",
        "for i in range(20):\n",
        "    convert_list=[]\n",
        "    a=temp_list.astype('float64')\n",
        "    for value in  data['vector'][i].split(','):\n",
        "        if value[0]=='[':\n",
        "            value=float(value[1:])\n",
        "        elif value[len(value)-1]==']':\n",
        "            value=float(value[:-1])\n",
        "        else :\n",
        "            value=float(value)\n",
        "        convert_list.append(value)\n",
        "    b=np.array(convert_list)\n",
        "#     print(a.shape)\n",
        "#     print(b.shape)\n",
        "#     b=b.astype('float64')\n",
        "    result =dot(a,b)/((norm(a)*norm(b)))\n",
        "    similar_documents[i][0]=i+1\n",
        "    similar_documents[i][1]=result\n",
        "similar_documents=similar_documents[similar_documents[:, 1].argsort()]\n",
        "similar_documents=np.flipud(similar_documents)\n",
        "print(similar_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61cc7d58",
      "metadata": {
        "id": "61cc7d58"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "e47d8e53946cd25c78f6cb33d23c4a8bf49779c2528cd6cfcd4b2b3e95edc55d"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}